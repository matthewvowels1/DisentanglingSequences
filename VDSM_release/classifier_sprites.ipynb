{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "from natsort import natsorted\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torch.optim\n",
    "\n",
    "# see https://github.com/yatindandi/Disentangled-Sequential-Autoencoder/blob/master/classifier.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set filename and parameters\n",
    "root = './codes/release_test/'\n",
    "nc = 3\n",
    "seq_len = 8\n",
    "imsize = 64\n",
    "test_frac = 0.3\n",
    "files = natsorted(os.listdir(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and preprocess the data\n",
    "id_codes_files = []\n",
    "action_codes_files = []\n",
    "labels_files = []\n",
    "recon_files = []\n",
    "test_img_files = []\n",
    "\n",
    "for file in files:\n",
    "    if 'dynamics' in file and 'label' not in file:\n",
    "        action_codes_files.append(file)\n",
    "    elif 'id' in file and 'label' not in file:\n",
    "        id_codes_files.append(file)\n",
    "    elif 'labels' in file:\n",
    "        labels_files.append(file)\n",
    "    elif 'recon' in file:\n",
    "        recon_files.append(file)\n",
    "    elif 'test_images' in file:\n",
    "        test_img_files.append(file)\n",
    "        \n",
    "         \n",
    "id_codes = []\n",
    "action_codes = []\n",
    "labels = []\n",
    "recon_gen = []\n",
    "test_imgs = []\n",
    "\n",
    "for file in id_codes_files:\n",
    "    id_codes.append(np.load(os.path.join(root, model, file))['arr_0'])\n",
    "for file in action_codes_files:\n",
    "    action_codes.append(np.load(os.path.join(root, model, file))['arr_0'])\n",
    "np_load_old = np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "for file in labels_files:\n",
    "    labels.append(np.load(os.path.join(root, model, file))['arr_0'])\n",
    "for file in test_img_files:\n",
    "    test_imgs.append(np.load(os.path.join(root,model,file))['arr_0'])\n",
    "for file in recon_files:\n",
    "    recon_gen.append(np.load(os.path.join(root,model,file))['arr_0'])\n",
    "np.load = np_load_old\n",
    "    \n",
    "id_codes = np.asarray(id_codes)\n",
    "print(id_codes.shape, id_codes[1,0,0,0])\n",
    "id_codes = id_codes.reshape(-1, id_codes.shape[-1])\n",
    "print(id_codes.shape, id_codes[10,0])\n",
    "action_codes = np.asarray(action_codes)\n",
    "print(action_codes.shape, action_codes[1,0,0])\n",
    "action_codes = action_codes.reshape(-1, action_codes.shape[-1])\n",
    "print(action_codes.shape, action_codes[10,0])\n",
    "recon_gen = np.asarray(recon_gen)\n",
    "print(recon_gen.shape, recon_gen[1,0,0,0,0,0])\n",
    "recon_gen = recon_gen.reshape(recon_gen.shape[0]*recon_gen.shape[1], seq_len, nc, imsize, imsize)        \n",
    "print(recon_gen.shape, recon_gen[10,0,0,0,0])\n",
    "test_imgs = np.asarray(test_imgs)\n",
    "test_imgs = test_imgs.reshape(test_imgs.shape[0]*test_imgs.shape[1], seq_len, nc, imsize, imsize)\n",
    "\n",
    "bodies = []\n",
    "shirts = []\n",
    "pants = []\n",
    "hairs = []\n",
    "actions = []\n",
    "for i in range(len(labels)):\n",
    "    num_in_batch = len(labels[0].item()['body'])\n",
    "    \n",
    "    for j in range(num_in_batch):\n",
    "        bodies.append(labels[i].item()['body'][j])\n",
    "        shirts.append(labels[i].item()['shirt'][j])\n",
    "        pants.append(labels[i].item()['pant'][j])\n",
    "        hairs.append(labels[i].item()['hair'][j])\n",
    "        actions.append(labels[i].item()['action'][j])\n",
    "bodies = np.asarray(bodies).reshape(-1, 1)\n",
    "shirts = np.asarray(shirts).reshape(-1, 1)\n",
    "pants = np.asarray(pants).reshape(-1, 1)\n",
    "hairs = np.asarray(hairs).reshape(-1, 1)\n",
    "actions = np.asarray(actions).reshape(-1, 1)\n",
    "labels = np.concatenate((bodies, shirts, pants, hairs, actions), 1)\n",
    "\n",
    "index = np.random.randint(len(labels), size=len(labels))\n",
    "test_indices = index[:int(len(labels)*test_frac)]\n",
    "train_indices = index[int(len(labels)*test_frac):]\n",
    "\n",
    "real_imgs_tr = test_imgs[train_indices]\n",
    "real_imgs_te = test_imgs[test_indices]\n",
    "gen_imgs_tr = recon_gen[train_indices]\n",
    "gen_imgs_te = recon_gen[test_indices]\n",
    "labels_tr = labels[train_indices]\n",
    "labels_te = labels[test_indices]\n",
    "print(real_imgs_tr.shape, real_imgs_te.shape)\n",
    "\n",
    "real_fake_train = np.concatenate((real_imgs_tr, gen_imgs_tr),0)\n",
    "real_fake_test = np.concatenate((real_imgs_te, gen_imgs_te),0)\n",
    "labels_both_train = np.concatenate((labels_tr, labels_tr), 0)\n",
    "labels_both_te = np.concatenate((labels_te, labels_te), 0)\n",
    "\n",
    "action_codes_tr = action_codes[train_indices]\n",
    "action_codes_te = action_codes[test_indices]\n",
    "id_codes_tr = id_codes[train_indices]\n",
    "id_codes_te = id_codes[test_indices]\n",
    "\n",
    "print(real_imgs_tr.shape, real_imgs_te.shape)\n",
    "print(action_codes_tr.shape, action_codes_te.shape)\n",
    "print(id_codes_tr.shape, id_codes_te.shape)\n",
    "real_fake_train = np.concatenate((real_imgs_tr, gen_imgs_tr),0)\n",
    "real_fake_test = np.concatenate((real_imgs_te, gen_imgs_te),0)\n",
    "labels_both_train = np.concatenate((labels_tr, labels_tr), 0)\n",
    "labels_both_te = np.concatenate((labels_te, labels_te), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define datasets\n",
    "class Sprites(data.Dataset):\n",
    "    def __init__(self, imgs, labels):\n",
    "        self.imgs = imgs\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        imgs = self.imgs[idx]\n",
    "        labels = self.labels[idx]\n",
    "        return imgs, labels\n",
    "\n",
    "class Codes(data.Dataset):\n",
    "    def __init__(self, codes, labels):\n",
    "        self.codes = codes\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.codes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        codes = self.codes[idx]\n",
    "        labels = self.labels[idx]\n",
    "        return codes, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define classifier model and metrics\n",
    "\n",
    "class SpriteClassifier(nn.Module):\n",
    "    def __init__(self, n_bodies=7, n_shirts=4, n_pants=5, n_hairstyles=6, n_actions=9,\n",
    "                 num_frames=8, in_size=64, channels=64, code_dim=1024, hidden_dim=512, nonlinearity=None):\n",
    "        super(SpriteClassifier, self).__init__()\n",
    "        nl = nn.LeakyReLU(0.2) if nonlinearity is None else nonlinearity\n",
    "        encoding_conv = []\n",
    "        encoding_conv.append(nn.Sequential(nn.Conv2d(3, channels, 5, 4, 1, bias=False), nl))\n",
    "        size = in_size // 4\n",
    "        self.num_frames = num_frames\n",
    "        while size > 4:\n",
    "            encoding_conv.append(nn.Sequential(\n",
    "                nn.Conv2d(channels, channels * 2, 5, 4, 1, bias=False),\n",
    "                nn.BatchNorm2d(channels * 2), nl))\n",
    "            size = size // 4\n",
    "            channels *= 2\n",
    "        self.encoding_conv = nn.Sequential(*encoding_conv)\n",
    "        self.final_size = size\n",
    "        self.final_channels = channels\n",
    "        self.code_dim = code_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.encoding_fc = nn.Sequential(\n",
    "                nn.Linear(size * size * channels, code_dim),\n",
    "                nn.BatchNorm1d(code_dim), nl)\n",
    "        # The last hidden state of a convolutional LSTM over the scenes is used for classification\n",
    "        self.classifier_lstm = nn.LSTM(code_dim, hidden_dim, batch_first=True, bidirectional=False)\n",
    "        self.body = nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "                nn.BatchNorm1d(hidden_dim // 2), nl,\n",
    "                nn.Linear(hidden_dim // 2, n_bodies))\n",
    "        self.shirt = nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "                nn.BatchNorm1d(hidden_dim // 2), nl,\n",
    "                nn.Linear(hidden_dim // 2, n_shirts))\n",
    "        self.pants = nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "                nn.BatchNorm1d(hidden_dim // 2), nl,\n",
    "                nn.Linear(hidden_dim // 2, n_pants))\n",
    "        self.hairstyles = nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "                nn.BatchNorm1d(hidden_dim // 2), nl,\n",
    "                nn.Linear(hidden_dim // 2, n_hairstyles))\n",
    "        self.action = nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "                nn.BatchNorm1d(hidden_dim // 2), nl,\n",
    "                nn.Linear(hidden_dim // 2, n_actions))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, x.size(2), x.size(3), x.size(4))\n",
    "        x = self.encoding_conv(x)\n",
    "        x = x.view(-1, self.final_channels * (self.final_size ** 2))\n",
    "        x = self.encoding_fc(x)\n",
    "        x = x.view(-1, self.num_frames, self.code_dim)\n",
    "        # Classifier output depends on last layer of LSTM: Can also change this to a bi-LSTM if required\n",
    "        _, (hidden, _) = self.classifier_lstm(x)\n",
    "        hidden = hidden.view(-1, self.hidden_dim)\n",
    "        return self.body(hidden), self.shirt(hidden), self.pants(hidden), self.hairstyles(hidden), self.action(hidden)\n",
    "\n",
    "def check_accuracy(model, test_data, device):\n",
    "    total = 0\n",
    "    correct_body = 0\n",
    "    correct_shirt = 0\n",
    "    correct_pant = 0\n",
    "    correct_hair = 0\n",
    "    correct_action = 0\n",
    "    with torch.no_grad():\n",
    "        for item in test_data:\n",
    "            image, label = item\n",
    "            image = image.to(device)\n",
    "            body = label[:, 0].to(device)\n",
    "            shirt = label[:, 1].to(device)\n",
    "            pant = label[:, 2].to(device)\n",
    "            hair = label[:, 3].to(device)\n",
    "            action = label[:, 4].to(device)\n",
    "            pred_body, pred_shirt, pred_pant, pred_hair, pred_action = model(image)\n",
    "            _, pred_body = torch.max(pred_body.data, 1)\n",
    "            _, pred_shirt = torch.max(pred_shirt.data, 1)\n",
    "            _, pred_pant = torch.max(pred_pant.data, 1)\n",
    "            _, pred_hair = torch.max(pred_hair.data, 1)\n",
    "            _, pred_action = torch.max(pred_action.data, 1)\n",
    "            total += body.size(0)\n",
    "            correct_body += (pred_body == body).sum().item()\n",
    "            correct_shirt += (pred_shirt == shirt).sum().item()\n",
    "            correct_pant += (pred_pant == pant).sum().item()\n",
    "            correct_hair += (pred_hair == hair).sum().item()\n",
    "            correct_action += (pred_action == action).sum().item()\n",
    "    print('Accuracy, Body : {} Shirt : {} Pant : {} Hair : {} Action {}'.format(correct_body/total, correct_shirt/total, correct_pant/total, correct_hair/total, correct_action/total)) \n",
    "\n",
    "\n",
    "def train_classifier(model, optim, train_data, device, epochs, path, test_data, start=0):\n",
    "    model.train()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(start, epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, item in enumerate(train_data, 1):\n",
    "            image, label = item\n",
    "            image = image.to(device)\n",
    "            body = label[:, 0].to(device)\n",
    "            shirt = label[:, 1].to(device)\n",
    "            pant = label[:, 2].to(device)\n",
    "            hair = label[:, 3].to(device)\n",
    "            action = label[:, 4].to(device)\n",
    "            pred_body, pred_shirt, pred_pant, pred_hair, pred_action = model(image)\n",
    "            loss = criterion(pred_body, body) + criterion(pred_shirt, shirt) + criterion(pred_pant, pant) + criterion(pred_hair, hair) + criterion(pred_action, action)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            running_loss += loss.item()\n",
    "        print('Epoch {} Avg Loss {}'.format(epoch + 1, running_loss / i))\n",
    "#         save_model(model, optim, epoch, path)\n",
    "        check_accuracy(model, test_data, device)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# init model and train\n",
    "device = torch.device('cuda:0')\n",
    "model = SpriteClassifier()\n",
    "model.to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.0004)\n",
    "\n",
    "sprites_train = Sprites(real_fake_train, labels_both_train)\n",
    "# sprites_test = Sprites(real_fake_test, labels_both_te)\n",
    "# sprites_train = Sprites(real_imgs_tr, labels_tr)\n",
    "sprites_test = Sprites(gen_imgs_te, labels_te)\n",
    "loader = data.DataLoader(sprites_train, batch_size=32, shuffle=True, num_workers=4)\n",
    "loader_test = data.DataLoader(sprites_test, batch_size=64, shuffle=True, num_workers=4)\n",
    "train_classifier(model, optim, loader, device, 50, './checkpoint_classifier.pth', loader_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# compare real image preds against fake image preds\n",
    "bs = 2\n",
    "real_test = Sprites(real_imgs_te, labels_te)\n",
    "fake_test = Sprites(gen_imgs_te, labels_te)\n",
    "real_loader = data.DataLoader(real_test, batch_size=bs, shuffle=False, num_workers=4)\n",
    "fake_loader = data.DataLoader(fake_test, batch_size=bs, shuffle=False, num_workers=4)\n",
    "\n",
    "total = 0\n",
    "correct_body = 0\n",
    "correct_shirt = 0\n",
    "correct_pant = 0\n",
    "correct_hair = 0\n",
    "correct_action = 0\n",
    "model.eval()\n",
    "for i, (item_real, item_fake) in enumerate(zip(real_loader, fake_loader)):\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "    fake_image, _ = item_fake\n",
    "    fake_image = fake_image.to(device)\n",
    "    image, _ = item_real\n",
    "    image = image.to(device)\n",
    "    im_check = image[0,0].permute(1,2,0).detach().cpu().numpy()\n",
    "    im_check_fake = fake_image[0,0].permute(1,2,0).detach().cpu().numpy()\n",
    "\n",
    "    # real\n",
    "    pred_body, pred_shirt, pred_pant, pred_hair, pred_action = model(image)\n",
    "    _, pred_body = torch.max(pred_body.data, 1)\n",
    "    _, pred_shirt = torch.max(pred_shirt.data, 1)\n",
    "    _, pred_pant = torch.max(pred_pant.data, 1)\n",
    "    _, pred_hair = torch.max(pred_hair.data, 1)\n",
    "    _, pred_action = torch.max(pred_action.data, 1)\n",
    "    # fake\n",
    "    fake_pred_body, fake_pred_shirt, fake_pred_pant, fake_pred_hair, fake_pred_action = model(fake_image)\n",
    "    _, fake_pred_body = torch.max(fake_pred_body.data, 1)\n",
    "    _, fake_pred_shirt = torch.max(fake_pred_shirt.data, 1)\n",
    "    _, fake_pred_pant = torch.max(fake_pred_pant.data, 1)\n",
    "    _, fake_pred_hair = torch.max(fake_pred_hair.data, 1)\n",
    "    _, fake_pred_action = torch.max(fake_pred_action.data, 1)\n",
    "    total += pred_body.size(0)\n",
    "    correct_body += (pred_body == fake_pred_body).sum().item()\n",
    "    correct_shirt += (pred_shirt == fake_pred_shirt).sum().item()\n",
    "    correct_pant += (pred_pant == fake_pred_pant).sum().item()\n",
    "    correct_hair += (pred_hair == fake_pred_hair).sum().item()\n",
    "    correct_action += (pred_action == fake_pred_action).sum().item()\n",
    "print('Accuracy, Body : {} Shirt : {} Pant : {} Hair : {} Action {}'.format(correct_body/total, correct_shirt/total, correct_pant/total, correct_hair/total, correct_action/total)) \n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now test disentanglement using the id vs action codes\n",
    "    \n",
    "class CodeClassifier(nn.Module):\n",
    "    def __init__(self, n_bodies=7, n_shirts=4, n_pants=5, n_hairstyles=6, n_actions=9,\n",
    "                  in_size=15, code_dim=15, hidden_dim=256, nonlinearity=None):\n",
    "        super(CodeClassifier, self).__init__()\n",
    "        nl = nn.LeakyReLU(0.2) if nonlinearity is None else nonlinearity\n",
    "\n",
    "        self.code_dim = code_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.encoding_fc = nn.Sequential(\n",
    "                nn.Linear(in_size, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim), nl)\n",
    "        \n",
    "        self.body = nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "                nn.BatchNorm1d(hidden_dim // 2), nl,\n",
    "                nn.Linear(hidden_dim // 2, n_bodies))\n",
    "        self.shirt = nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "                nn.BatchNorm1d(hidden_dim // 2), nl,\n",
    "                nn.Linear(hidden_dim // 2, n_shirts))\n",
    "        self.pants = nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "                nn.BatchNorm1d(hidden_dim // 2), nl,\n",
    "                nn.Linear(hidden_dim // 2, n_pants))\n",
    "        self.hairstyles = nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "                nn.BatchNorm1d(hidden_dim // 2), nl,\n",
    "                nn.Linear(hidden_dim // 2, n_hairstyles))\n",
    "        self.action = nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "                nn.BatchNorm1d(hidden_dim // 2), nl,\n",
    "                nn.Linear(hidden_dim // 2, n_actions))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoding_fc(x)\n",
    "        return self.body(x), self.shirt(x), self.pants(x), self.hairstyles(x), self.action(x)\n",
    "    \n",
    "       \n",
    "    \n",
    "device = torch.device('cuda:0')\n",
    "model = CodeClassifier(in_size=30)\n",
    "model.to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
    "\n",
    "sprites_train = Codes(id_codes_tr, labels_tr)\n",
    "# sprites_test = Sprites(real_fake_test, labels_both_te)\n",
    "# sprites_train = Sprites(real_imgs_tr, labels_tr)\n",
    "sprites_test = Codes(id_codes_te, labels_te)\n",
    "loader = data.DataLoader(sprites_train, batch_size=32, shuffle=True, num_workers=4)\n",
    "loader_test = data.DataLoader(sprites_test, batch_size=32, shuffle=True, num_workers=4)\n",
    "train_classifier(model, optim, loader, device, 50, './checkpoint_classifier.pth', loader_test) \n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "model = CodeClassifier(in_size=10)\n",
    "model.to(device)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=0.0004)\n",
    "\n",
    "sprites_train = Codes(action_codes_tr, labels_tr)\n",
    "# sprites_test = Sprites(real_fake_test, labels_both_te)\n",
    "# sprites_train = Sprites(real_imgs_tr, labels_tr)\n",
    "sprites_test = Codes(action_codes_te, labels_te)\n",
    "loader = data.DataLoader(sprites_train, batch_size=32, shuffle=True, num_workers=4)\n",
    "loader_test = data.DataLoader(sprites_test, batch_size=32, shuffle=True, num_workers=4)\n",
    "train_classifier(model, optim, loader, device, 100, './checkpoint_classifier.pth', loader_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
